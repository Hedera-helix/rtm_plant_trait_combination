{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d46978-1b67-4da4-a655-a4986bb8aca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81d4770-0e15-47d2-b1aa-cbd6e22cfb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bdb8df-00c2-4789-84b6-379ecd1e04b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set directory to the plot_folder folder\n",
    "os.chdir('/net/home/dmederer/Transferability_efficient/plot_folder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a49ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from CSV into a DataFrame\n",
    "data_predictions_start = pd.read_csv('Predictions_combined_rtm_only.csv') \n",
    "data_observations_start = pd.read_csv('Observations_combined_rtm_only.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7605349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the suffix from the column names in data_predictions\n",
    "data_predictions_start.columns = data_predictions_start.columns.str.replace(' Predictions', '')\n",
    "data_predictions_start\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fddcda-fe59-4734-a825-2719c372245a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now use the same concept as in the cell before to loop through all the variables\n",
    "# and print the slope and intercept for each variable\n",
    "# Print it with proper captions\n",
    "for column in data_predictions_start.columns:\n",
    "    data_observations = data_observations_start\n",
    "    data_predictions = data_predictions_start\n",
    "    # remove all rows in column 'LMA (g/m²)' with NaN values from data_observations\n",
    "    data_observations = data_observations.dropna(subset=[column])\n",
    "    # using the index remove all rows from data_predictions that are not in data_observations\n",
    "    data_predictions = data_predictions[data_predictions.index.isin(data_observations.index)]\n",
    "    X = data_predictions[column].values.reshape(-1, 1)\n",
    "    y = data_observations[column].values.reshape(-1, 1)\n",
    "    model = LinearRegression()\n",
    "    model.fit(X, y)\n",
    "\n",
    "    # Obtain residuals\n",
    "    y_pred = model.predict(X)\n",
    "    residuals = y - y_pred\n",
    "\n",
    "    # Calculate residual standard error (RSE) or root mean squared error (RMSE)\n",
    "    n = len(y)\n",
    "    p = X.shape[1] if isinstance(X, np.ndarray) else X.shape[1] + 1\n",
    "    rse = np.sqrt(np.sum(residuals**2) / (n - p))\n",
    "\n",
    "    # save the print statements to a text file\n",
    "    with open('Slope_intercept_rtm_only.txt', 'a') as f:\n",
    "        print('Slope: ', model.coef_[0][0], file=f)\n",
    "        print('Intercept: ', model.intercept_[0], file=f)\n",
    "        print('RSE: ', rse, file=f)\n",
    "        print('Variable: ', column, file=f)\n",
    "        print(' ', file=f)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eccddcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAME THING FOR REAL DATA\n",
    "\n",
    "# Load the data from CSV into a DataFrame\n",
    "data_predictions_start = pd.read_csv('Predictions_combined_real_only.csv') \n",
    "data_observations_start = pd.read_csv('Observations_combined_real_only.csv') \n",
    "\n",
    "# Remove the suffix from the column names in data_predictions\n",
    "data_predictions_start.columns = data_predictions_start.columns.str.replace(' Predictions', '')\n",
    "data_predictions_start\n",
    "\n",
    "# Now use the same concept as in the cell before to loop through all the variables\n",
    "# and print the slope and intercept for each variable\n",
    "# Print it with proper captions\n",
    "for column in data_predictions_start.columns:\n",
    "    data_observations = data_observations_start\n",
    "    data_predictions = data_predictions_start\n",
    "    # remove all rows in column 'LMA (g/m²)' with NaN values from data_observations\n",
    "    data_observations = data_observations.dropna(subset=[column])\n",
    "    # using the index remove all rows from data_predictions that are not in data_observations\n",
    "    data_predictions = data_predictions[data_predictions.index.isin(data_observations.index)]\n",
    "    X = data_predictions[column].values.reshape(-1, 1)\n",
    "    y = data_observations[column].values.reshape(-1, 1)\n",
    "    model = LinearRegression()\n",
    "    model.fit(X, y)\n",
    "    # Obtain residuals\n",
    "    y_pred = model.predict(X)\n",
    "    residuals = y - y_pred\n",
    "\n",
    "    # Calculate residual standard error (RSE) or root mean squared error (RMSE)\n",
    "    n = len(y)\n",
    "    p = X.shape[1] if isinstance(X, np.ndarray) else X.shape[1] + 1\n",
    "    rse = np.sqrt(np.sum(residuals**2) / (n - p))\n",
    "\n",
    "    # save the print statements to a text file\n",
    "    with open('Slope_intercept_real_only.txt', 'a') as f:\n",
    "        print('Slope: ', model.coef_[0][0], file=f)\n",
    "        print('Intercept: ', model.intercept_[0], file=f)\n",
    "        print('RSE: ', rse, file=f)\n",
    "        print('Variable: ', column, file=f)\n",
    "        print(' ', file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22996658-c1e6-47a3-9363-69e3b769286f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predicted vs. observed values\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X, y, color='blue', label='Observed vs. Predicted')\n",
    "plt.plot(X, model.predict(X), color='red', label='Linear Regression')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Observed Values')\n",
    "# make sure that x and y axis have the same scale, using the maximum value for y\n",
    "plt.xlim(0, max(y))\n",
    "plt.ylim(0, max(y))\n",
    "#Include the slope and intercept in the down right corner of the plot\n",
    "plt.text(0.1, 0.9, 'Slope: ' + str(round(model.coef_[0][0], 2)), transform=plt.gca().transAxes)\n",
    "plt.text(0.1, 0.8, 'Intercept: ' + str(round(model.intercept_[0], 2)), transform=plt.gca().transAxes)\n",
    "plt.title('Assessing Bias with Linear Regression')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567ff6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST RESIDUALS\n",
    "from scipy.stats import wilcoxon\n",
    "\n",
    "# Load the data from CSV into a DataFrame\n",
    "data_predictions_rtm = pd.read_csv('Predictions_combined_rtm_only.csv')\n",
    "data_observations_rtm = pd.read_csv('Observations_combined_rtm_only.csv')\n",
    "\n",
    "data_predictions_real_only = pd.read_csv('Predictions_combined_real_only.csv')\n",
    "data_observations_real_only = pd.read_csv('Observations_combined_real_only.csv')\n",
    "\n",
    "# Remove the suffix from the column names in data_predictions\n",
    "data_predictions_rtm.columns = data_predictions_rtm.columns.str.replace(' Predictions', '')\n",
    "data_predictions_real_only.columns = data_predictions_real_only.columns.str.replace(' Predictions', '')\n",
    "\n",
    "\n",
    "for column in data_predictions_rtm.columns:\n",
    "    data_observations_rtm_active = data_observations_rtm\n",
    "    data_predictions_rtm_active = data_predictions_rtm\n",
    "\n",
    "    data_observations_real_active = data_observations_real_only\n",
    "    data_predictions_real_active = data_predictions_real_only\n",
    "\n",
    "    # remove all rows in column with NaN values from data_observations\n",
    "    data_observations_rtm_active = data_observations_rtm_active.dropna(subset=[column])\n",
    "    data_observations_real_active = data_observations_real_active.dropna(subset=[column])\n",
    "    # using the index remove all rows from data_predictions that are not in data_observations\n",
    "    data_predictions_rtm_active = data_predictions_rtm_active[data_predictions_rtm_active.index.isin(data_observations_rtm_active.index)]\n",
    "    data_predictions_real_active = data_predictions_real_active[data_predictions_real_active.index.isin(data_observations_real_active.index)]\n",
    "\n",
    "    # Calculate residuals\n",
    "    residuals_rtm = data_observations_rtm_active[column] - data_predictions_rtm_active[column]\n",
    "    residuals_real = data_observations_real_active[column] - data_predictions_real_active[column]\n",
    "\n",
    "    # Perform one-sided Wilcoxon signed-rank test\n",
    "    test_statistic, p_value = wilcoxon(residuals_rtm, residuals_real, alternative='less')\n",
    "\n",
    "    # Save the results to a text file\n",
    "    with open('Wilcoxon_test_less_rtm_only.txt', 'a') as f:\n",
    "        print('Variable: ', column, file=f)\n",
    "        print(f\"Test Statistic: {test_statistic}\", file=f)\n",
    "        print(f\"P-value: {p_value}\", file=f)\n",
    "        print(' ', file=f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37850d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals_rtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f63619d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now load the two text files with the slope and intercept values\n",
    "# and save them to a DataFrame\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Read the text file\n",
    "with open('Slope_intercept_rtm.txt', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Initialize lists to store parsed values\n",
    "slope = []\n",
    "intercept = []\n",
    "variable = []\n",
    "rse = []\n",
    "\n",
    "# Parse the content and extract values\n",
    "for i in range(0, len(lines), 5):\n",
    "    slope_val = float(lines[i].split(':')[1].strip())\n",
    "    intercept_val = float(lines[i + 1].split(':')[1].strip())\n",
    "    rse_val = float(lines[i + 2].split(':')[1].strip())\n",
    "    variable_val = lines[i + 3].split(':')[1].strip()\n",
    "    \n",
    "    slope.append(slope_val)\n",
    "    intercept.append(intercept_val)\n",
    "    variable.append(variable_val)\n",
    "    rse.append(rse_val)\n",
    "\n",
    "# Create a DataFrame\n",
    "data = {\n",
    "    'Slope': slope,\n",
    "    'Intercept': intercept,\n",
    "    'RSE': rse,\n",
    "    'Variable': variable\n",
    "}\n",
    "\n",
    "df_rtm = pd.DataFrame(data)\n",
    "\n",
    "print(df_rtm)\n",
    "\n",
    "\n",
    "# Read the text file\n",
    "with open('Slope_intercept_real_only.txt', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Initialize lists to store parsed values\n",
    "slope = []\n",
    "intercept = []\n",
    "variable = []\n",
    "rse = []\n",
    "\n",
    "# Parse the content and extract values\n",
    "for i in range(0, len(lines), 5):\n",
    "    slope_val = float(lines[i].split(':')[1].strip())\n",
    "    intercept_val = float(lines[i + 1].split(':')[1].strip())\n",
    "    rse_val = float(lines[i + 2].split(':')[1].strip())\n",
    "    variable_val = lines[i + 3].split(':')[1].strip()\n",
    "    \n",
    "    slope.append(slope_val)\n",
    "    intercept.append(intercept_val)\n",
    "    variable.append(variable_val)\n",
    "    rse.append(rse_val)\n",
    "\n",
    "# Create a DataFrame\n",
    "data = {\n",
    "    'Slope': slope,\n",
    "    'Intercept': intercept,\n",
    "    'RSE': rse,\n",
    "    'Variable': variable\n",
    "}\n",
    "\n",
    "df_real_only = pd.DataFrame(data)\n",
    "\n",
    "print(df_real_only)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9096905e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each variable, calculate the difference between the slopes of the two models and divide it\n",
    "# by the root of the difference of the standard errors of the two slopes\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Calculate the effect size for each variable\n",
    "result_values = []\n",
    "\n",
    "variables = df_rtm['Variable'].unique()\n",
    "\n",
    "for var in variables:\n",
    "    slope_values_1 = df_rtm[df_rtm['Variable'] == var]['Slope']\n",
    "    slope_values_2 = df_real_only[df_real_only['Variable'] == var]['Slope']\n",
    "\n",
    "    rse_values_1 = df_rtm[df_rtm['Variable'] == var]['RSE']\n",
    "    rse_values_2 = df_real_only[df_real_only['Variable'] == var]['RSE']\n",
    "    \n",
    "    # Calculate the difference between the slopes\n",
    "    slope_difference = slope_values_1.mean() - slope_values_2.mean()\n",
    "    \n",
    "    # Calculate the root of the sum of the standard errors\n",
    "    se_root_sum = np.sqrt(rse_values_1.mean()**2 + rse_values_2.mean()**2)\n",
    "    \n",
    "    # Calculate the effect size\n",
    "    test_val = slope_difference / se_root_sum\n",
    "\n",
    "    result_values.append(var)\n",
    "    result_values.append(test_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325e8d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f49a70d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f156f725",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "# Perform Mann-Whitney U test for each variable\n",
    "variables = df_rtm['Variable'].unique()\n",
    "\n",
    "for var in variables:\n",
    "    slope_values_1 = df_rtm[df_rtm['Variable'] == var]['Slope']\n",
    "    slope_values_2 = df_real_only[df_real_only['Variable'] == var]['Slope']\n",
    "    \n",
    "    # Perform the Mann-Whitney U test\n",
    "    statistic, p_value = mannwhitneyu(slope_values_1, slope_values_2)\n",
    "    \n",
    "    print(f\"Variable: {var}\")\n",
    "    print(f\"Mann-Whitney U Statistic: {statistic}\")\n",
    "    print(f\"P-value: {p_value}\")\n",
    "    print(f\"Significant Difference: {p_value < 0.05}\")  # Assuming alpha = 0.05\n",
    "    print(\"-----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49278e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Additional step: get absolute values of residuals and plot their distribution \n",
    "\n",
    "# Load the data from CSV into a DataFrame\n",
    "data_predictions_rtm = pd.read_csv('Predictions_combined_low_var.csv')\n",
    "data_observations_rtm = pd.read_csv('Observations_combined_low_var.csv')\n",
    "\n",
    "data_predictions_real_only = pd.read_csv('Predictions_combined_real_only.csv')\n",
    "data_observations_real_only = pd.read_csv('Observations_combined_real_only.csv')\n",
    "\n",
    "# Remove the suffix from the column names in data_predictions\n",
    "data_predictions_rtm.columns = data_predictions_rtm.columns.str.replace(' Predictions', '')\n",
    "data_predictions_real_only.columns = data_predictions_real_only.columns.str.replace(' Predictions', '')\n",
    "\n",
    "\n",
    "for column in data_predictions_rtm.columns:\n",
    "    data_observations_rtm_active = data_observations_rtm\n",
    "    data_predictions_rtm_active = data_predictions_rtm\n",
    "\n",
    "    data_observations_real_active = data_observations_real_only\n",
    "    data_predictions_real_active = data_predictions_real_only\n",
    "\n",
    "    # remove all rows in column with NaN values from data_observations\n",
    "    data_observations_rtm_active = data_observations_rtm_active.dropna(subset=[column])\n",
    "    data_observations_real_active = data_observations_real_active.dropna(subset=[column])\n",
    "    # using the index remove all rows from data_predictions that are not in data_observations\n",
    "    data_predictions_rtm_active = data_predictions_rtm_active[data_predictions_rtm_active.index.isin(data_observations_rtm_active.index)]\n",
    "    data_predictions_real_active = data_predictions_real_active[data_predictions_real_active.index.isin(data_observations_real_active.index)]\n",
    "\n",
    "    # Calculate absolute values of residuals\n",
    "    residuals_rtm = np.abs(data_observations_rtm_active[column] - data_predictions_rtm_active[column])\n",
    "    residuals_real = np.abs(data_observations_real_active[column] - data_predictions_real_active[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1a9e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals_rtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bf73a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc778300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of residuals\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.distplot(residuals_rtm, label='RTM')\n",
    "sns.distplot(residuals_real, label='Real')\n",
    "plt.xlabel('Absolute Residuals')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Distribution of Absolute Residuals')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683d6822",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
