{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04650105",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import process, fuzz\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "os.chdir('/Users/danielmederer/Data Storage Folder')\n",
    "os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095c3115",
   "metadata": {},
   "outputs": [],
   "source": [
    "######### Guide to Script\n",
    "\n",
    "# First a mapping between TRY names and eyadata(Ecosis) names has to be created\n",
    "# This mapping ensures that the two datasets use the same naming scheme\n",
    "# Mapping has to be done with eyadata and TRY hierarchy data\n",
    "# Once the mapping is done once, the processing steps for TRY and Ecosis can be done separately \n",
    "# and can be repeated for adjustments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80d7083",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Eyadata loading \n",
    "\n",
    "data = pd.read_csv('/Users/danielmederer/Data Storage Folder/test_new.csv', sep = \",\", encoding = 'latin-1')\n",
    "\n",
    "# remove unused columns and rows with NA species\n",
    "data.drop(['Unnamed: 0', 'dataset', 'Site', 'Year', 'numSamples', 'LandCover', 'Tool'],axis=1,inplace=True)\n",
    "data.dropna(subset=[\"Species\"],inplace=True)\n",
    "data.drop(data.iloc[:, 30:], axis = 1, inplace=True)\n",
    "data.sample(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1233e1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load hierarchy data for matching\n",
    "\n",
    "hierarchy_data = pd.read_csv('/Users/danielmederer/Data Storage Folder/hierarchy.info.csv', sep = \",\", encoding='latin_1')\n",
    "hierarchy_data.drop(['Unnamed: 0', 'ObservationID'],axis=1,inplace=True)\n",
    "\n",
    "hierarchy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aaf7f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ecosis Species + new names\n",
    "list_of_strings = data.dropna(subset=[\"Species\"])[\"Species\"].unique()\n",
    "#dataset['Species'].unique()\n",
    "# inter.dropna(subset=[\"Species\"])[\"Species\"].unique() \n",
    "mapp=[]\n",
    "\n",
    "####Try names\n",
    "names=hierarchy_data.dropna(subset=[\"Species\"])[\"Species\"].unique()\n",
    "\n",
    "for i in range(hierarchy_data['Species'].nunique()):\n",
    "    print(i)\n",
    "    mapp.append((process.extract(names[i], list_of_strings, limit=1)[0])+(names[i],))    \n",
    "mapp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d770c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_name = list(zip(*mapp))\n",
    "\n",
    "traits_df = pd.DataFrame({\"EcosisName\":tr_name[0],'ratio':tr_name[1],'TryName':tr_name[2]})\n",
    "\n",
    "traits_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff2ed81",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Clean and select the mapping ##\n",
    "\n",
    "#tuples with ratio >89\n",
    "mapping=traits_df[traits_df['ratio']>89]\n",
    "mapping.sort_values(by=['ratio'],inplace=True) #####Sort the tuples according to the ration\n",
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7677a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Species'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2867b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####Drop duplicate duples and keep the one with the highest ratio values:last has most of the time the highest ratio\n",
    "mapping.drop_duplicates(subset=['EcosisName'], keep='last',inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977efb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####check for duplicates\n",
    "ids = mapping[\"EcosisName\"]\n",
    "mapping[ids.isin(ids[ids.duplicated(keep=False)])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfa40ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "###drop null values in EcosisName\n",
    "mapping.dropna(subset=[\"EcosisName\"],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e505eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ce9d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping.to_csv('SpeciesMapping_test_NotNullMore89.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33333c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = pd.read_csv('/Users/danielmederer/Data Storage Folder/SpeciesMapping_test_NotNullMore89.csv',\n",
    "                      sep = \",\")\n",
    "#mapping.drop(['Unnamed: 0'],axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d787f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cd0d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Hierarchy mapping join\n",
    "\n",
    "#Add the eya mapping name to hierarchy database\n",
    "F=mapping.merge(hierarchy_data, left_on='TryName',\n",
    "    right_on='Species', how='left')\n",
    "\n",
    "####Number of unique Species names for the mapping\n",
    "print(F['TryName'].nunique()) \n",
    "print(F['EcosisName'].nunique()) \n",
    "\n",
    "F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb92151",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Ecosis mapping join \n",
    "\n",
    "#Add the mapping to eyadata\n",
    "D = data.merge(mapping, left_on='Species',\n",
    "    right_on='EcosisName', how='left')\n",
    "\n",
    "####Number of unique Species names for the mapping\n",
    "print(D['TryName'].nunique()) \n",
    "print(D['EcosisName'].nunique())\n",
    "\n",
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f66bcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "D.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c705fa46",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Processing of Eya's data ##\n",
    "\n",
    "# Remove NAs, both columns and rows (if all are NA)\n",
    "# columns\n",
    "eyadata_processed = D[pd.notnull(D['TryName'])]\n",
    "# rows\n",
    "eyadata_processed = eyadata_processed.dropna(axis = 0, how = 'all', subset = ['Al content (mg/cmÂ²)', 'Aluminum concentration (mg/g)',\n",
    "       'Anthocyanin content (Î¼g/cmÂ²)', 'Anthocyanin concentration (mg/g)',\n",
    "       'Boron content (mg/cmÂ²)', 'Boron concentration (mg/g)',\n",
    "       'C content (mg/cmÂ²)', 'C concentration (mg/g)', 'Ca content (mg/cmÂ²)',\n",
    "       'Ca concentration (mg/g)', 'Carotenoid content (Î¼g/cmÂ²)',\n",
    "       'Carotenoid concentration (mg/g)', 'Cellulose (mg/cmÂ²)',\n",
    "       'Cellulose (mg/g)', 'Chl content (Î¼g/cmÂ²)',\n",
    "       'Chlorophyll concentration (mg/g)', 'Copper content (mg/cmÂ²)',\n",
    "       'Copper concentration (mg/g)', 'EWT (mg/cmÂ²)', 'Fiber (mg/cmÂ²)',\n",
    "       'Fiber (mg/g)', 'Flavonoids concentration (mg/g)',\n",
    "       'Flavonoids content (mg/cmÂ²)', 'Iron content (mg/cmÂ²)',\n",
    "       'Iron concentration (mg/g)', 'LAI (mÂ²/mÂ²)', 'LMA (g/mÂ²)',\n",
    "       'LDMC (g/g)', 'LWC (%)'])\n",
    "####Number of not null Species names for the mapping\n",
    "print(eyadata_processed['TryName'].notnull().sum())\n",
    "\n",
    "# Remove Species column\n",
    "eyadata_processed.drop(['Species'],axis=1,inplace=True)\n",
    "\n",
    "# Make TryName the first column\n",
    "eyadata_processed.insert(0, 'Species', eyadata_processed['TryName'])\n",
    "# Remove rest of unnecessary columns\n",
    "eyadata_processed.drop(['EcosisName', 'ratio', 'TryName'],axis=1,inplace=True)\n",
    "\n",
    "\n",
    "eyadata_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c825ed32",
   "metadata": {},
   "outputs": [],
   "source": [
    "eyadata_processed['Species'].nunique()\n",
    "\n",
    "eyadata_processed.to_csv('eyadata_processed_finished1.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0ebd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "################ \n",
    "################\n",
    "# Only relevant for Eya's data \n",
    "eyadata_processed = pd.read_csv('/Users/danielmederer/Data Storage Folder/eyadata_processed_finished1.csv')\n",
    "\n",
    "hierarchy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce56dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "eyadata_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9f6221",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Hierarchy join with eyadata \n",
    "\n",
    "# Remove duplicates of Hierarchy (so they are not used in merge)\n",
    "hierarchy_data.drop_duplicates(inplace=True)\n",
    "\n",
    "#Add the eyadata to hierarchy_data\n",
    "hierarchy_processed = eyadata_processed.merge(hierarchy_data, left_on='Species',\n",
    "    right_on='Species', how='left')\n",
    "\n",
    "####Number of unique Species names for the mapping\n",
    "print(hierarchy_processed['Species'].nunique()) \n",
    "\n",
    "hierarchy_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299e76e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hierarchy_processed = hierarchy_processed.loc[:, ['Species', 'Genus', 'Family']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a20319",
   "metadata": {},
   "outputs": [],
   "source": [
    "hierarchy_processed.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bae6c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "hierarchy_processed.to_csv('hierarchy_processed.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d1f11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "#########\n",
    "#########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa9f356",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "######## TRYdata ########\n",
    "\n",
    "data = pd.read_csv('/Users/danielmederer/Data Storage Folder/TRY_processed_unfinished.csv', sep = \",\")\n",
    "\n",
    "data.sample(15)\n",
    "\n",
    "# Load hierarchy data for matching\n",
    "\n",
    "hierarchy_data = pd.read_csv('/Users/danielmederer/Data Storage Folder/hierarchy.info.csv', sep = \",\", encoding='latin_1')\n",
    "hierarchy_data.drop(['Unnamed: 0', 'ObservationID'],axis=1,inplace=True)\n",
    "\n",
    "## Specific for TRY data ##\n",
    "\n",
    "data.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcd9296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional: subset TRY for shorter processing times\n",
    "\n",
    "data = data.iloc[:, [0, 1, 2, 4, 5, 8, 9, 10, 12, 14, 15, 16, 17, 18, 19, 20, 21, 25, 26]]\n",
    "#data = data.iloc[:, [0, 1, 2, 8, 10, 12, 14]]\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a071b977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with all NA (due to subset) => make subset from first to last variable of interest\n",
    "c = data.loc[:0, 'Dispersal unit length':'Wood vessel element length; stem conduit (vessel and tracheids) element length'].columns  # retrieve only the 0th row for efficiency\n",
    "data = data.dropna(axis = 0, subset = c, how = 'all') \n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054bbf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Merge TRYdata with Hierarchy data\n",
    "D = data.merge(hierarchy_data, left_on='Species',\n",
    "    right_on='Species', how='left')\n",
    "\n",
    "####Number of unique Species names for the mapping\n",
    "print(D['Species'].nunique()) \n",
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdddfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(D['ObservationID'].nunique()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3ec25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(D['ObsDataID'].nunique()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a377b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all duplicate observations that were produced by the merging based on ObsDataID (!)\n",
    "\n",
    "D.drop_duplicates(subset = 'ObsDataID', keep = \"first\", inplace = True)\n",
    "\n",
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d52271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove NAs, both columns and rows (if all are NA)\n",
    "\n",
    "# columns\n",
    "TRYdata_processed = D[pd.notnull(D['Species'])]\n",
    "# rows\n",
    "TRYdata_processed = TRYdata_processed.dropna(axis = 0, how = 'all') \n",
    "\n",
    "# Remove rows that contain zeros\n",
    "TRYdata_processed = TRYdata_processed[(TRYdata_processed != 0).all(1)]\n",
    "\n",
    "## Number of non-null Species names for the mapping\n",
    "print(TRYdata_processed['Species'].notnull().sum())\n",
    "\n",
    "# Remove Species column\n",
    "#TRYdata_processed.drop(['Species'],axis=1,inplace=True)\n",
    "\n",
    "# Make TryName the first column\n",
    "#TRYdata_processed.insert(0, 'Species', TRYdata_processed['TryName'])\n",
    "# Remove rest of unnecessary columns\n",
    "#TRYdata_processed.drop(['EcosisName', 'ratio', 'TryName'],axis=1,inplace=True)\n",
    "\n",
    "\n",
    "TRYdata_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c0ff2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "\n",
    "TRYdata_processed.columns = [\"Species\", \"ObservationID\", \"ObsDataID\", \"DispersalUL_mm\", \"LA_mm2\", \n",
    "                             \"SLA_mm2mg\", \"carbonc_mgg\", \"chlc_mygcm2\", \n",
    "                      \"LDMC_gg\", \"nitrogenc_gm2\", \"nitrogenc_mgg\", \"D15N_permill\", \n",
    "                      \"N_P_ratio_gg\", \"phosphorc_mgg\", \"LWC_LDM_notsat_gg\", \"plant_height_m\", \n",
    "                      \"seed_mass_mg\", \"SSD_gcm3\", \"ConduitEL_mym\", \"Genus\", \"Family\"]\n",
    "\n",
    "#TRYdata_processed.columns = [\"Species\", \"ObservationID\", \"ObsDataID\", \"SLA_mm2mg\", \"chlc_mygcm2\", \n",
    "                             #\"LDMC_gg\", \"nitrogenc_gm2\", \"Genus\", \"Family\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58bc975",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRYdata_processed.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1f1d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group dataframe by observation to have all entries of one observation in one row\n",
    "\n",
    "grouped_df = TRYdata_processed.groupby('ObservationID').agg({'Species': 'first',\n",
    "                                                'DispersalUL_mm': 'first',\n",
    "                                                'LA_mm2': 'first',\n",
    "                                                'SLA_mm2mg': 'first',\n",
    "                                                'carbonc_mgg': 'first',\n",
    "                                                'chlc_mygcm2': 'first',\n",
    "                                                'LDMC_gg': 'first',\n",
    "                                                'nitrogenc_gm2': 'first',\n",
    "                                                'nitrogenc_mgg': 'first',             \n",
    "                                                'D15N_permill': 'first',\n",
    "                                                'N_P_ratio_gg': 'first',\n",
    "                                                'phosphorc_mgg': 'first',\n",
    "                                                'LWC_LDM_notsat_gg': 'first',\n",
    "                                                'plant_height_m': 'first',\n",
    "                                                'seed_mass_mg': 'first',\n",
    "                                                'SSD_gcm3': 'first',\n",
    "                                                'ConduitEL_mym': 'first',\n",
    "                                                'Genus': 'first',\n",
    "                                                'Family': 'first',\n",
    "                                                            })\n",
    "'''grouped_df = TRYdata_processed.groupby('ObservationID').agg({'Species': 'first',\n",
    "                                                'SLA_mm2mg': 'first',\n",
    "                                                'chlc_mygcm2': 'first',\n",
    "                                                'LDMC_gg': 'first',\n",
    "                                                'nitrogenc_gm2': 'first',\n",
    "                                                'Genus': 'first',\n",
    "                                                'Family': 'first',\n",
    "                                                            })'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5252b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f81ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make and save dataframe for trait values\n",
    "\n",
    "TRY_values_processed = grouped_df.iloc[:, 1:17] # adapt for subsets!\n",
    "TRY_values_processed.to_csv('TRY_values_processed_finished.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239498cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRY_values_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee07bc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make and save dataframe for hierarchy\n",
    "TRY_hierarchy_processed = grouped_df[[\"Species\", \"Genus\", \"Family\"]]\n",
    "TRY_hierarchy_processed.to_csv('TRY_hierarchy_processed_finished.csv', index = True) # True to create index column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9fc5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRY_hierarchy_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332744f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## General saving scripts ##\n",
    "\n",
    "grouped_df['Species'].nunique()\n",
    "\n",
    "grouped_df.to_csv('TRYdata_processed_finished.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c23e66e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427dcce5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d6b256",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
